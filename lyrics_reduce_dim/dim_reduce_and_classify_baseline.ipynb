{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linea Base\n",
    "----------\n",
    "\n",
    "Usando las letras en expañol entrenar un sistema que devuelva una representacion en una dimension baja, despues entrenar un clasificador con esas representaciones.\n",
    "\n",
    "Hay distintas opciones para obtener representaciones de las letras, una puede ser entrenando nuevos word vectors y despues sumarlos para obtener la representacion de la letra. La primera que vamos a usar es countvectorizer y luego PCA o SVD para reducir dimension (tambien podría ser T-sne).\n",
    "\n",
    "Para entrenar word vectors con gensim: https://www.analyticsvidhya.com/blog/2017/06/word-embeddings-count-word2veec/\n",
    "Otro, con representacion de baja dimension: https://machinelearningmastery.com/develop-word-embeddings-python-gensim/\n",
    "Jurafsky capitulo 16 (representacion usando SVD): https://web.stanford.edu/~jurafsky/slp3/16.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "stop_words = [\"de\",\"la\", \"que\",\"el\",\"en\",\"y\",\"a\",\"los\",\"del\",\"se\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se intentará usar LDA para transformar las letras (800k) en una representación vectorial para luego entrenar un clasificador y comparar el desempeño. Se realiza incialmente para una dimension de 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dimentions = 10\n",
    "folder = 'data/test-full-lyrics/es'\n",
    "\n",
    "vectorizer = HashingVectorizer(stop_words=stop_words, non_negative=True)#, alternate_sign=False)\n",
    "dim_reduce = LatentDirichletAllocation(dimentions, random_state=42)\n",
    "count = 0\n",
    "spanish_lyrics = []\n",
    "for filename in os.listdir(folder):\n",
    "    f = open(folder+'/'+filename)\n",
    "    lyric = json.load(f)\n",
    "    spanish_lyrics.append(\"\\n\".join(lyric)) # falta un \" \" ?\n",
    "\n",
    "    # We train LDA in batches\n",
    "    if count == 5000:\n",
    "        X_train = vectorizer.transform(spanish_lyrics)\n",
    "        dim_reduce.partial_fit(X_train)\n",
    "        count = 0\n",
    "    count += 1\n",
    "pickle.dump(dim_reduce, open('data/lda.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from todotango_cleaner import clean_dates\n",
    "\n",
    "#vectorizer = HashingVectorizer(stop_words=stop_words, non_negative=True)\n",
    "vectorizer = HashingVectorizer(stop_words=stop_words, non_negative=True, n_features=4000)\n",
    "#dim_reduce = pickle.load(open('data/lda.p'))\n",
    "years = clean_dates.get_years()\n",
    "\n",
    "\n",
    "tango_lyrics_file = 'data/clean/lyrics.json'\n",
    "tango_lyrics = json.load(open(tango_lyrics_file))\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "y_orig = []\n",
    "for work_id in tango_lyrics.keys():  \n",
    "    if int(work_id) in years:\n",
    "        if years[int(work_id)] < 2017:\n",
    "            y_orig.append(years[int(work_id)])\n",
    "            y.append(years[int(work_id)] > 1950)\n",
    "            X.append(tango_lyrics[work_id])\n",
    "    \n",
    "X_vect = vectorizer.transform(X)\n",
    "#X_transf = dim_reduce.transform(X_vect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se compara la clasificacion usando los vectores generados a partir de la transformacion contra los vectores originales del HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.76716918  0.72673931  0.73260687  0.72590109  0.73154362]\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='linear')\n",
    "scores = cross_val_score(clf, X_vect, y, cv=5)\n",
    "print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.51758794  0.51802179  0.51802179  0.51802179  0.51761745]\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='linear')\n",
    "scores = cross_val_score(clf, X_transf, y, cv=5)\n",
    "#y_pred = cross_val_predict(clf, X_transf, y, cv=5)\n",
    "#conf_mat = confusion_matrix(y, y_pred)\n",
    "print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "cnt = Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False 0.517854149204\n",
      "True 0.482145850796\n"
     ]
    }
   ],
   "source": [
    "for k in cnt.keys():\n",
    "    print k, float(cnt[k])/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Regresión ***\n",
    "================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-19.87076785 -19.73238833 -18.93854635]\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "#from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "clf = SVR('linear')\n",
    "scores = cross_val_score(clf, X_vect, y_orig, cv=3, scoring='neg_mean_absolute_error')\n",
    "\n",
    "print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
